{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from urllib.request import urlopen\nimport timm\nimport torch\nimport zipfile,os\nfrom PIL import Image\nfrom pathlib import Path\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader,Dataset\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-09-22T20:02:49.876247Z","iopub.execute_input":"2025-09-22T20:02:49.876560Z","iopub.status.idle":"2025-09-22T20:02:49.881602Z","shell.execute_reply.started":"2025-09-22T20:02:49.876519Z","shell.execute_reply":"2025-09-22T20:02:49.880762Z"},"trusted":true},"outputs":[],"execution_count":56},{"cell_type":"code","source":"pip install roboflow","metadata":{"execution":{"iopub.status.busy":"2025-09-22T20:02:49.917985Z","iopub.execute_input":"2025-09-22T20:02:49.918168Z","iopub.status.idle":"2025-09-22T20:02:53.326689Z","shell.execute_reply.started":"2025-09-22T20:02:49.918154Z","shell.execute_reply":"2025-09-22T20:02:53.325594Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.2.9)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.6.15)\nRequirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\nRequirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7.2)\nRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.26.4)\nRequirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\nRequirement already satisfied: pi-heif<2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.0)\nRequirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.5.2)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\nRequirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.1.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.4)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\nRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.5.0)\nRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\nRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\nRequirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\nRequirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->roboflow) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.58.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.0.9)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->roboflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->roboflow) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.5->roboflow) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.5->roboflow) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.5->roboflow) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"pip install scikit-learn==1.3.1","metadata":{"execution":{"iopub.status.busy":"2025-09-22T20:02:53.328549Z","iopub.execute_input":"2025-09-22T20:02:53.328796Z","iopub.status.idle":"2025-09-22T20:02:56.657775Z","shell.execute_reply.started":"2025-09-22T20:02:53.328773Z","shell.execute_reply":"2025-09-22T20:02:56.656611Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn==1.3.1 in /usr/local/lib/python3.11/dist-packages (1.3.1)\nRequirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.1) (1.26.4)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.1) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.1) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.1) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.1) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"from roboflow import Roboflow\nrf = Roboflow(api_key=\"B5AgQrixtU1h66djOZMm\")\nproject = rf.workspace(\"digihack\").project(\"lung-disease-pbtdg\")\nversion = project.version(1)\ndataset = version.download(\"folder\")","metadata":{"execution":{"iopub.status.busy":"2025-09-22T20:02:56.659119Z","iopub.execute_input":"2025-09-22T20:02:56.659403Z","iopub.status.idle":"2025-09-22T20:02:57.435553Z","shell.execute_reply.started":"2025-09-22T20:02:56.659376Z","shell.execute_reply":"2025-09-22T20:02:57.434975Z"},"trusted":true},"outputs":[{"name":"stdout","text":"loading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"from roboflow import Roboflow\nrf = Roboflow(api_key=\"Q1flzyg1J8Z2OMweLXf3\")\nproject = rf.workspace(\"weapon-mpr3p\").project(\"lung-disease-rybev\")\nversion = project.version(1)\ndataset2 = version.download(\"folder\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T20:02:57.437380Z","iopub.execute_input":"2025-09-22T20:02:57.437637Z","iopub.status.idle":"2025-09-22T20:02:58.219169Z","shell.execute_reply.started":"2025-09-22T20:02:57.437607Z","shell.execute_reply":"2025-09-22T20:02:58.218546Z"}},"outputs":[{"name":"stdout","text":"loading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"train_dir = dataset.location + \"/train\"\ntest_dir = dataset2.location + \"/train\"\nval_dir = dataset.location + \"/valid\"","metadata":{"execution":{"iopub.status.busy":"2025-09-22T20:02:58.219856Z","iopub.execute_input":"2025-09-22T20:02:58.220118Z","iopub.status.idle":"2025-09-22T20:02:58.223957Z","shell.execute_reply.started":"2025-09-22T20:02:58.220095Z","shell.execute_reply":"2025-09-22T20:02:58.223285Z"},"trusted":true},"outputs":[],"execution_count":61},{"cell_type":"code","source":"model = timm.create_model(\n    'swin_base_patch4_window7_224',\n    pretrained=True,\n    num_classes=5,\n)\n#if torch.cuda.device_count() > 1:\n#    model = nn.DataParallel(model)\n\nmodel = model.eval()\n\n# get model specific transforms (normalization, resize)\ndata_config = timm.data.resolve_model_data_config(model)\ntrans = timm.data.create_transform(**data_config, is_training=False)","metadata":{"execution":{"iopub.status.busy":"2025-09-22T20:02:58.224776Z","iopub.execute_input":"2025-09-22T20:02:58.225043Z","iopub.status.idle":"2025-09-22T20:03:01.787479Z","shell.execute_reply.started":"2025-09-22T20:02:58.225021Z","shell.execute_reply":"2025-09-22T20:03:01.786883Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b74e0fdbb41746398db385c72ad24aef"}},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.images = []\n        self.labels = []\n        self.class_names = os.listdir(data_dir)\n\n        for label, class_name in enumerate(self.class_names):\n            class_dir = os.path.join(data_dir, class_name)\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                self.images.append(img_path)\n                self.labels.append(label)\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label  # Ensure this returns a tuple of (image, label)\n","metadata":{"execution":{"iopub.status.busy":"2025-09-22T20:03:01.788229Z","iopub.execute_input":"2025-09-22T20:03:01.788451Z","iopub.status.idle":"2025-09-22T20:03:01.794765Z","shell.execute_reply.started":"2025-09-22T20:03:01.788433Z","shell.execute_reply":"2025-09-22T20:03:01.794028Z"},"trusted":true},"outputs":[],"execution_count":63},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n# Create an instance of the CustomDataset\ndataset = CustomDataset(data_dir=train_dir, transform=transform)\n\ntrain_loader = DataLoader(dataset, batch_size=4, shuffle=True)\nfor data in train_loader:\n    print(data[0].shape)  # This will show you the structure of the data being returned\n    inputs, targets = data  # Unpack only if it has the correct structure\n    break","metadata":{"execution":{"iopub.status.busy":"2025-09-22T20:03:01.795517Z","iopub.execute_input":"2025-09-22T20:03:01.795782Z","iopub.status.idle":"2025-09-22T20:03:01.861080Z","shell.execute_reply.started":"2025-09-22T20:03:01.795766Z","shell.execute_reply":"2025-09-22T20:03:01.860269Z"},"trusted":true},"outputs":[{"name":"stdout","text":"torch.Size([4, 3, 224, 224])\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# ==============================\n# DEVICE & MODEL\n# ==============================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbest_val_loss = float('inf') \nsave_path = \"./best_model.pth\"\nearly_stop_patience = 5   # Early stopping patience\nno_improve_epochs = 0     # Counter untuk early stopping\n\n# Asumsikan model sudah ada\n# model = ...\nmodel.to(device)\n\n# ==============================\n# LOSS & OPTIMIZER\n# ==============================\ncriterion = nn.CrossEntropyLoss().to(device)\n\n# Weight decay sudah otomatis di AdamW\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n\n# Scheduler (Reduce LR on Plateau berdasarkan val_loss)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, \n    mode='min',       # monitor loss -> semakin kecil semakin baik\n    factor=0.5,       # turunkan LR setengah kali lipat\n    patience=2,       # kalau 2 epoch berturut-turut tidak membaik\n    verbose=True\n)\n\n# ==============================\n# VALIDATION LOADER\n# ==============================\ntry:\n    val_dataset = ImageFolder(root=val_dir, transform=transform)\n    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\nexcept NameError:\n    print(\"Pastikan variabel 'val_dir' dan 'transform' sudah didefinisikan.\")\n    val_loader = None\n\n# ==============================\n# TRAINING LOOP\n# ==============================\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    # ---------------- TRAINING ----------------\n    model.train()\n    epoch_loss = 0\n    correct_predictions = 0\n    total_samples = 0\n    all_targets, all_preds = [], []\n    \n    progress_bar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] Training\")\n    for inputs, targets in progress_bar:\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        # ✅ accumulate true per-sample loss\n        epoch_loss += loss.item() * targets.size(0)\n        total_samples += targets.size(0)\n\n        # Accuracy\n        _, predicted = torch.max(outputs.data, 1)\n        correct_predictions += (predicted == targets).sum().item()\n        all_preds.extend(predicted.cpu().numpy())\n        all_targets.extend(targets.cpu().numpy())\n        \n        progress_bar.set_postfix(loss=loss.item())\n\n    avg_loss = epoch_loss / total_samples   # ✅ per-sample average\n    accuracy = correct_predictions / total_samples * 100\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        all_targets, all_preds, average='weighted', zero_division=0\n    )\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n          f\"Train Loss: {avg_loss:.4f}, \"\n          f\"Train Acc: {accuracy:.2f}%, \"\n          f\"Train F1: {f1:.4f}\")\n\n    # ---------------- VALIDATION ----------------\n    if val_loader:\n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n        all_val_targets, all_val_preds = [], []\n\n        with torch.no_grad():\n            val_progress_bar = tqdm(val_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] Validation\")\n            for inputs, targets in val_progress_bar:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n\n                # ✅ accumulate true per-sample loss\n                val_loss += loss.item() * targets.size(0)\n                val_total += targets.size(0)\n\n                _, predicted = torch.max(outputs.data, 1)\n                val_correct += (predicted == targets).sum().item()\n                all_val_preds.extend(predicted.cpu().numpy())\n                all_val_targets.extend(targets.cpu().numpy())\n\n        avg_val_loss = val_loss / val_total   # ✅ per-sample average\n        val_accuracy = val_correct / val_total * 100\n        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n            all_val_targets, all_val_preds, average='weighted', zero_division=0\n        )\n\n        print(f\"             Val Loss: {avg_val_loss:.4f}, \"\n              f\"Val Acc: {val_accuracy:.2f}%, \"\n              f\"Val F1: {val_f1:.4f}\\n\")\n\n        # Update scheduler\n        scheduler.step(avg_val_loss)\n\n        # Save best model\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), save_path)\n            print(f\"✅ Best model saved at epoch {epoch+1} | Val Loss: {best_val_loss:.4f}\")\n            no_improve_epochs = 0\n        else:\n            no_improve_epochs += 1\n            print(f\"⚠️ No improvement for {no_improve_epochs} epoch(s).\")\n\n        # Early stopping\n        if no_improve_epochs >= early_stop_patience:\n            print(\"⏹ Early stopping triggered.\")\n            break\n\n# Save last model\ntorch.save(model.state_dict(), \"./last_model.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2025-09-22T20:03:01.861973Z","iopub.execute_input":"2025-09-22T20:03:01.862249Z","execution_failed":"2025-09-22T20:03:25.602Z"},"trusted":true},"outputs":[{"name":"stderr","text":"The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\nEpoch [1/100] Training:   7%|▋         | 104/1513 [00:21<04:41,  5.01it/s, loss=1.94]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import csv\nimport os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport timm\n\n# ==============================\n# CUSTOM DATASET WITH PATHS\n# ==============================\nclass ImageFolderWithPaths(ImageFolder):\n    \"\"\"Custom dataset that includes image file paths.\"\"\"\n    def __getitem__(self, index):\n        # Normal ImageFolder return (img, label)\n        original_tuple = super().__getitem__(index)\n        path = self.samples[index][0]  # file path\n        return original_tuple + (path,)  # (img, label, path)\n\n# ==============================\n# DATASET & LOADER\n# ==============================\ntest_dataset = ImageFolderWithPaths(root=test_dir, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# ==============================\n# DEVICE\n# ==============================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ==============================\n# MODEL\n# ==============================\nmodel = timm.create_model(\n    'mobilevitv2_100.cvnets_in1k',\n    pretrained=True,\n    num_classes=5,   # sesuai dataset\n)\n\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)\n\nmodel.to(device)\n\n# ==============================\n# LOAD BEST MODEL\n# ==============================\nstate_dict = torch.load(\"./best_model.pth\", map_location=device)\nif isinstance(model, nn.DataParallel):\n    model.module.load_state_dict(state_dict)\nelse:\n    model.load_state_dict(state_dict)\n\nmodel.eval()\nprint(\"✅ Loaded best_model.pth successfully.\")\n\n# ==============================\n# PREDICTION LOOP\n# ==============================\nresults = []\n\nwith torch.no_grad():\n    for inputs, _, paths in test_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, dim=1)\n\n        for path, pred in zip(paths, preds.cpu().numpy()):\n            filename = os.path.basename(path)\n\n            # ✅ Clean up Roboflow suffix like \".rf.xxxxx\"\n            if \".rf.\" in filename:\n                filename = filename.split(\".rf.\")[0]\n\n            results.append([filename, pred])\n\n# ==============================\n# SAVE CSV\n# ==============================\ncsv_file = \"test_predictions.csv\"\nwith open(csv_file, mode=\"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerow([\"Id\", \"Predicted\"])  # header\n    writer.writerows(results)\n\nprint(f\"✅ Predictions saved to {csv_file}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T20:03:25.603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/working/test_predictions.csv\")\ndf","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T20:03:25.603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}